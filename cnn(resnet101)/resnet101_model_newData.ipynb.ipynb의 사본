{"cells":[{"cell_type":"markdown","metadata":{"id":"A6B0L8JnBJZU"},"source":["## 1. 필요한 패키지 불러오기 및 Parameter 구성하기"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7677,"status":"ok","timestamp":1729091712060,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"Hg_YNZlCNogO","outputId":"29e8a0fc-f137-4b33-d15b-0d8ebe4e618a"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import pickle\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n","from torchsummary import summary\n","# Seed 설정 --> 코드를 돌릴때 random값을 동일하게 해주기 위해\n","random.seed(10)\n","np.random.seed(123)\n","torch.manual_seed(123)\n","torch.cuda.manual_seed(123)\n","\n","\n","# GPU사용을 위한 설정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","# 모델 파라미터 설정\n","config = {\n","          'data_stats'  : [[], [0.2313007198154599]],\n","          'data_stats_64_3000' : [[0.059319619673050376], [0.23133441623990797]],\n","          'data_stats_128_1000' : [[0.029937755134580656], [0.1669103758131807]],\n","          'data_stats_pickle' : [[0.059267916], [0.23123889]],\n","          'batch_size'  : 128,\n","          'worker'      : 2,\n","          'epochs'      : 100,\n","          'momentum'    : 0.9,\n","          'lr_decay'    : 0.0005,\n","          'SGD_lr'      : 0.01,\n","          'Adam_lr'     : 0.001,\n","          'overfitting_count' : 10,\n","          }\n","#'data_stats'  : [[0.05929394720093303], [0.2313007198154599]],  64*64\n","#[[0.02996110809515722], [0.16695794835875627]]   128*128\n","# 'Cifar10_stats': [[0.49139965, 0.48215845, 0.4465309],\n","#                             [0.20220213, 0.19931543, 0.20086348]],\n","#,  [[0.05927349984094634], [0.23126395485830378]],  64 * 64 * 3000"]},{"cell_type":"markdown","metadata":{"id":"jDC7z8GXCggj"},"source":["## 2. 데이터 가져오기"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37216,"status":"ok","timestamp":1729091749274,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"Dpxa9rdFdz31","outputId":"4e458327-3036-4f26-859f-0c2b6d22f833"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502,"status":"ok","timestamp":1729091749774,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"CEATRVcZeRjB","outputId":"1313cfba-49e8-4b16-f7e0-caa717bc0171"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1R8w9Au88wZukHx9BnC0_U6CoaYSOY2IO/집교1팀플\n"]}],"source":["%cd /content/drive/MyDrive/집중교육/팀프로젝트/집교1팀플"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1265,"status":"ok","timestamp":1729091751037,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"tDyBVbX845AH","outputId":"c958e016-fa80-47f2-a1da-03feb2b47a43"},"outputs":[{"output_type":"stream","name":"stdout","text":[" get_5_prediction.ipynb   mobilenet_64_3000.pth                     resnet101_resnet18_64_3000.pth\n"," label_5000.npy          'model_64x3000_128*1000.ipynb'             resnet18_128_1000.pth\n"," label.npy                model.ipynb                               resnet18_64_3000.pth\n"," matrix_128_new.npy       model_teamProject_resnet101_64_3000.pth   rnn_model.pth\n"," matrix_128.npy           model_teamProject_resnet18_64_3000.pth   \u001b[0m\u001b[01;34m'top5 accuarcy'\u001b[0m/\n"," matrix_256.npy           \u001b[01;34mndjsonfiles\u001b[0m/                              vector_to_image.ipynb\n"," matrix_64.npy            \u001b[01;34mresnet101\u001b[0m/                                \u001b[01;34m데이터및라벨\u001b[0m\u001b[K/\n"," mobilenet_128_1000.pth   resnet101_64_3000.pth                    \u001b[01;34m'테스트 이미지'\u001b[0m\u001b[K/\n"]}],"source":["%ls"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1729091751037,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"SNXjtcLaUuDA"},"outputs":[],"source":["# input_data_path = './matrix_64.npy'\n","# input_label_path = './label_64.npy'\n","\n","# input_data_64_3000_path = './데이터및라벨/matrix_64_3000.npy'\n","# input_label_64_3000_path = './데이터및라벨/label_345x3000.npy'\n","\n","# input_data = './데이터및라벨/penPositions.pkl'\n","# input_label = './데이터및라벨/labels.pkl'\n","\n","input_data = './테스트 이미지/user_img.txt'\n"]},{"cell_type":"code","source":["_label = ['The Eiffel Tower', 'The Great Wall of China', 'The Mona Lisa', 'aircraft carrier', 'airplane', 'alarm clock', 'ambulance', 'angel', 'animal migration', 'ant', 'anvil', 'apple', 'arm', 'asparagus', 'axe', 'backpack', 'banana', 'bandage', 'barn', 'baseball bat', 'baseball', 'basket', 'basketball', 'bat', 'bathtub', 'beach', 'bear', 'beard', 'bed', 'bee', 'belt', 'bench', 'bicycle', 'binoculars', 'bird', 'birthday cake', 'blackberry', 'blueberry', 'book', 'boomerang', 'bottlecap', 'bowtie', 'bracelet', 'brain', 'bread', 'bridge', 'broccoli', 'broom', 'bucket', 'bulldozer', 'bus', 'bush', 'butterfly', 'cactus', 'cake', 'calculator', 'calendar', 'camel', 'camera', 'camouflage', 'campfire', 'candle', 'cannon', 'canoe', 'car', 'carrot', 'castle', 'cat', 'ceiling fan', 'cell phone', 'cello', 'chair', 'chandelier', 'church', 'circle', 'clarinet', 'clock', 'cloud', 'coffee cup', 'compass', 'computer', 'cookie', 'cooler', 'couch', 'cow', 'crab', 'crayon', 'crocodile', 'crown', 'cruise ship', 'cup', 'diamond', 'dishwasher', 'diving board', 'dog', 'dolphin', 'donut', 'door', 'dragon', 'dresser', 'drill', 'drums', 'duck', 'dumbbell', 'ear', 'elbow', 'elephant', 'envelope', 'eraser', 'eye', 'eyeglasses', 'face', 'fan', 'feather', 'fence', 'finger', 'fire hydrant', 'fireplace', 'firetruck', 'fish', 'flamingo', 'flashlight', 'flip flops', 'floor lamp', 'flower', 'flying saucer', 'foot', 'fork', 'frog', 'frying pan', 'garden hose', 'garden', 'giraffe', 'goatee', 'golf club', 'grapes', 'grass', 'guitar', 'hamburger', 'hammer', 'hand', 'harp', 'hat', 'headphones', 'hedgehog', 'helicopter', 'helmet', 'hexagon', 'hockey puck', 'hockey stick', 'horse', 'hospital', 'hot air balloon', 'hot dog', 'hot tub', 'hourglass', 'house plant', 'house', 'hurricane', 'ice cream', 'jacket', 'jail', 'kangaroo', 'key', 'keyboard', 'knee', 'knife', 'ladder', 'lantern', 'laptop', 'leaf', 'leg', 'light bulb', 'lighter', 'lighthouse', 'lightning', 'line', 'lion', 'lipstick', 'lobster', 'lollipop', 'mailbox', 'map', 'marker', 'matches', 'megaphone', 'mermaid', 'microphone', 'microwave', 'monkey', 'moon', 'mosquito', 'motorbike', 'mountain', 'mouse', 'moustache', 'mouth', 'mug', 'mushroom', 'nail', 'necklace', 'nose', 'ocean', 'octagon', 'octopus', 'onion', 'oven', 'owl', 'paint can', 'paintbrush', 'palm tree', 'panda', 'pants', 'paper clip', 'parachute', 'parrot', 'passport', 'peanut', 'pear', 'peas', 'pencil', 'penguin', 'piano', 'pickup truck', 'picture frame', 'pig', 'pillow', 'pineapple', 'pizza', 'pliers', 'police car', 'pond', 'pool', 'popsicle', 'postcard', 'potato', 'power outlet', 'purse', 'rabbit', 'raccoon', 'radio', 'rain', 'rainbow', 'rake', 'remote control', 'rhinoceros', 'rifle', 'river', 'roller coaster', 'rollerskates', 'sailboat', 'sandwich', 'saw', 'saxophone', 'school bus', 'scissors', 'scorpion', 'screwdriver', 'sea turtle', 'see saw', 'shark', 'sheep', 'shoe', 'shorts', 'shovel', 'sink', 'skateboard', 'skull', 'skyscraper', 'sleeping bag', 'smiley face', 'snail', 'snake', 'snorkel', 'snowflake', 'snowman', 'soccer ball', 'sock', 'speedboat', 'spider', 'spoon', 'spreadsheet', 'square', 'squiggle', 'squirrel', 'stairs', 'star', 'steak', 'stereo', 'stethoscope', 'stitches', 'stop sign', 'stove', 'strawberry', 'streetlight', 'string bean', 'submarine', 'suitcase', 'sun', 'swan', 'sweater', 'swing set', 'sword', 'syringe', 't-shirt', 'table', 'teapot', 'teddy-bear', 'telephone', 'television', 'tennis racquet', 'tent', 'tiger', 'toaster', 'toe', 'toilet', 'tooth', 'toothbrush', 'toothpaste', 'tornado', 'tractor', 'traffic light', 'train', 'tree', 'triangle', 'trombone', 'truck', 'trumpet', 'umbrella', 'underwear', 'van', 'vase', 'violin', 'washing machine', 'watermelon', 'waterslide', 'whale', 'wheel', 'windmill', 'wine bottle', 'wine glass', 'wristwatch', 'yoga', 'zebra', 'zigzag']"],"metadata":{"id":"6shJSoDQytjS","executionInfo":{"status":"ok","timestamp":1729091751037,"user_tz":-540,"elapsed":2,"user":{"displayName":"이도원","userId":"11243313302283747519"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3566,"status":"ok","timestamp":1729091754601,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"3zUe6aFjZNN9"},"outputs":[],"source":["# only_data_set = torch.from_numpy(np.load(input_data_path))\n","# label_set = torch.from_numpy(np.load(input_label_path))\n","# print(only_data_set.shape)\n","# print(label_set.shape)\n","\n","# data_set_64_3000 = torch.from_numpy(np.load(input_data_64_3000_path))\n","# label_set_64_3000 = torch.from_numpy(np.load(input_label_64_3000_path))\n","\n","# with open('./데이터및라벨/penPositions.pkl', 'rb') as f:\n","#     penPositions = pickle.load(f)\n","\n","# with open('./데이터및라벨/labels.pkl', 'rb') as f:\n","#     labels = pickle.load(f)\n","\n","import json\n","\n","image_array = []\n","labels = []\n","with open(input_data, 'r', encoding='utf-8') as file:\n","    for line in file:\n","        # 각 줄을 JSON 형식으로 파싱\n","        data = json.loads(line)\n","\n","        label = data.get('word', None)\n","\n","        if label.endswith(' false'):\n","            label = label[:-7]\n","\n","        if label not in _label:\n","            continue\n","\n","        drawing = data.get('drawing', None)\n","\n","        image_array.append(drawing)\n","        labels.append(_label.index(label))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1729091754602,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"8eZ0KsDqDCOc"},"outputs":[],"source":["# Bresenham's line algorithm을 이용하여 두 좌표를 연결하는 함수\n","def draw_line(x0, y0, x1, y1, matrix):\n","    dx = abs(x1 - x0)\n","    dy = abs(y1 - y0)\n","    sx = 1 if x0 < x1 else -1\n","    sy = 1 if y0 < y1 else -1\n","    err = dx - dy\n","\n","    while True:\n","        if 0 <= x0 < 64 and 0 <= y0 < 64:  # 좌표가 행렬 범위 내에 있을 때만 적용\n","            matrix[y0, x0] = 1  # 좌표를 1로 설정\n","        if x0 == x1 and y0 == y1:\n","            break\n","        e2 = err * 2\n","        if e2 > -dy:\n","            err -= dy\n","            x0 += sx\n","        if e2 < dx:\n","            err += dx\n","            y0 += sy\n","\n","# stroke_array를 받아서 CNN에 사용될 데이터를 반환하는 함수\n","def process_stroke_array(stroke_array):\n","    # CNN에 사용할 데이터 초기화\n","    cnn_data = np.zeros((1, 64, 64), dtype=np.uint8)\n","\n","    # 64x64 빈 행렬 생성\n","    matrix = np.zeros((64, 64), dtype=np.uint8)\n","\n","    # 각 좌표 간에 선을 그림\n","    for stroke in stroke_array:\n","        x_coords = stroke[0]\n","        y_coords = stroke[1]\n","\n","        # 좌표 값 조정\n","        x_coords = [int(x / 4) for x in x_coords]\n","        y_coords = [int(y / 4) for y in y_coords]\n","\n","        # Bresenham's line algorithm으로 좌표 간 선 그리기\n","        for i in range(len(x_coords) - 1):\n","            x0, y0 = x_coords[i], y_coords[i]\n","            x1, y1 = x_coords[i + 1], y_coords[i + 1]\n","            draw_line(x0, y0, x1, y1, matrix)\n","\n","    # 결과를 CNN 데이터에 추가\n","    cnn_data[0] = matrix\n","\n","    return cnn_data\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1729091754602,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"RFMr5No7FrYf"},"outputs":[],"source":["class CombinedPenDataset(Dataset):\n","    def __init__(self, pen_positions, labels):\n","        self.pen_positions = pen_positions\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.pen_positions)\n","\n","    def __getitem__(self, idx):\n","        pen_position = self.pen_positions[idx]\n","\n","        stroke_array = process_stroke_array(pen_position)  # CNN에 입력될 64x64 이미지\n","        stroke_tensor = torch.tensor(stroke_array, dtype=torch.float32)\n","\n","        label = self.labels[idx]\n","        label_tensor = torch.tensor(label, dtype=torch.long)\n","\n","        return stroke_tensor, label_tensor"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1729091754602,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"lGYr4s8nuryr"},"outputs":[],"source":["# 새로운 CombinedPenDataset 사용\n","combined_dataset = CombinedPenDataset(image_array, labels)\n","\n","# 데이터셋 크기 분할 (90% 훈련, 10% 테스트)\n","train_size = int(0.9 * len(combined_dataset))\n","test_size = len(combined_dataset) - train_size\n","\n","train_dataset, test_dataset = random_split(combined_dataset, [train_size, test_size])\n","# transform 적용\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(*config['data_stats_pickle']),\n","])\n","\n","# DataLoader 생성\n","trainloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n","# valloader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n","testloader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n","\n","\n","trainloader.transform = train_transform\n","# valloader.transform = valid_transform"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"3uph1HO4Nu-O","executionInfo":{"status":"ok","timestamp":1729091754602,"user_tz":-540,"elapsed":4,"user":{"displayName":"이도원","userId":"11243313302283747519"}}},"outputs":[],"source":["# train_transforms = transforms.Compose([\n","#     transforms.RandomHorizontalFlip(),\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(*config['data_stats_64_3000']), # mean = Cifar10_stats[0], std = Cifar10_stats[1]\n","# ])\n","\n","# valid_transforms = transforms.Compose([\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(*config['data_stats_64_3000']), # mean = Cifar10_stats[0], std = Cifar10_stats[1]\n","# ])\n","\n","# # apply transform\n","# train_dataset_64.transform = train_transforms\n","# validation_dataset_64.transform = valid_transforms\n","\n","# # Data Loader\n","# trainloader_64 = DataLoader(train_dataset_64, batch_size = config['batch_size'], shuffle = True, num_workers = config['worker'])\n","# validloader_64 = DataLoader(validation_dataset_64, batch_size = config['batch_size'], shuffle = False, num_workers = config['worker'])\n","\n","# # Class_name 저장\n","# # with open('./data/cifar-10-batches-py/batches.meta', 'rb') as f:\n","# #     batches_meta = pickle.load(f, encoding = 'latin1')\n","# # classes_name = list(batches_meta[sorted(list(batches_meta.keys()))[0]]) # airplane, automobile, ..., truck\n","# # print(classes_name)"]},{"cell_type":"markdown","metadata":{"id":"6U3Om6lkEQ5r"},"source":["## 3. trainloader 이미지 살펴보기\n","\n","CIFAR10데이터 가져오기에서 만든 trainloader에 이미지가 어떻게 저장되어있는지 이미지와 라벨을 같이 확인해본다."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"2xUbzcSINvJu","executionInfo":{"status":"ok","timestamp":1729091754602,"user_tz":-540,"elapsed":4,"user":{"displayName":"이도원","userId":"11243313302283747519"}}},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# import numpy as np\n","\n","# # trainloader의 이미지 확인\n","# dataiter = iter(trainloader)\n","# images, labels = next(dataiter)\n","# fig = plt.figure(figsize = (15, 5), dpi = 100)\n","# ax = fig.add_subplot(1,1,1)\n","# ax.imshow(torchvision.utils.make_grid(images, normalize = True).permute(1, 2, 0))\n","# plt.show()\n","\n","# # 해당 이미지의 label확인\n","# for i in range(len(images)):\n","#     if (i+1)%8==0:\n","#         print(f'{i+1}: {classes_name[labels[i]]}', end = '\\n')\n","#     else:\n","#         if len(classes_name[labels[i]]) >= 6:\n","#             print(f'{i+1}: {classes_name[labels[i]]}', end = '\\t')\n","#         else:\n","#             print(f'{i+1}: {classes_name[labels[i]]}', end = '  \\t')"]},{"cell_type":"markdown","metadata":{"id":"TrCinkAfDlE-"},"source":["## 4. 모델 정의"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1729091754602,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"rFlZDR6-Nz0I"},"outputs":[],"source":["class BottleNeck(nn.Module):\n","    expansion = 4\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","        self.residual_function = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias = False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size = 3, padding = 1, bias = False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(),\n","            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size = 1, bias = False),\n","            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n","        )\n","\n","        self.relu = nn.ReLU()\n","        self.shortcut = nn.Sequential()\n","\n","        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride = stride, kernel_size = 1, bias = False),\n","                nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n","            )\n","\n","    def forward(self, x):\n","        x = self.residual_function(x) + self.shortcut(x)\n","        x = self.relu(x)\n","        return x\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_block, num_classes=345):\n","        super().__init__()\n","\n","        self.in_channels = 64\n","\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n","        )\n","\n","        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n","        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n","        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n","        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n","\n","        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, 345)\n","\n","    def _make_layer(self, block, out_channels, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_channels, out_channels, stride))\n","            self.in_channels = out_channels * block.expansion\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        output = self.conv1(x)\n","        output = self.conv2_x(output)\n","        x = self.conv3_x(output)\n","        x = self.conv4_x(x)\n","        x = self.conv5_x(x)\n","        x = self.avg_pool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","def getResnetModel():\n","    return ResNet(BottleNeck, [2, 3, 22, 2])"]},{"cell_type":"markdown","metadata":{"id":"SykHBlc9DiVN"},"source":["## 5. 모델 학습 및 검증"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1729091754602,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"vmUlpsAOPpeq"},"outputs":[],"source":["from time import sleep\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":8249,"status":"ok","timestamp":1729091762847,"user":{"displayName":"이도원","userId":"11243313302283747519"},"user_tz":-540},"id":"goP4O0vd-Qkr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d4f1eab6-ec08-48d5-9233-85fdc45bffcd"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-e53a796becc5>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  original_model.load_state_dict(torch.load(fileName))\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}],"source":["def get_model(model_name):\n","    if model_name == 'resnet18':\n","        return getResnetModel()\n","    else:\n","        raise Exception(f\"{model_name} is not supported yet\")\n","\n","original_model = get_model('resnet18').to(device)\n","fileName = f'./resnet101_resnet18_64_3000.pth'\n","original_model.load_state_dict(torch.load(fileName))\n","\n","new_model_fine = get_model('resnet18').to(device)\n","new_model_fine.load_state_dict(original_model.state_dict())\n","\n","new_model_student = get_model('resnet18').to(device)\n","new_model_student.load_state_dict(original_model.state_dict())\n","\n","new_model_Rehearsal = get_model('resnet18').to(device)\n","new_model_Rehearsal.load_state_dict(original_model.state_dict())"]},{"cell_type":"code","source":["with open('./데이터및라벨/penPositions.pkl', 'rb') as f:\n","    penPositions = pickle.load(f)\n","\n","with open('./데이터및라벨/labels.pkl', 'rb') as f:\n","    labels = pickle.load(f)"],"metadata":{"id":"kXBfbWujz_mO","executionInfo":{"status":"ok","timestamp":1729091817534,"user_tz":-540,"elapsed":54688,"user":{"displayName":"이도원","userId":"11243313302283747519"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["config = {\n","          'data_stats'  : [[], [0.2313007198154599]],\n","          'data_stats_64_3000' : [[0.059319619673050376], [0.23133441623990797]],\n","          'data_stats_128_1000' : [[0.029937755134580656], [0.1669103758131807]],\n","          'data_stats_pickle' : [[0.059267916], [0.23123889]],\n","          'batch_size'  : 128,\n","          'worker'      : 2,\n","          'epochs'      : 100,\n","          'momentum'    : 0.9,\n","          'lr_decay'    : 0.0005,\n","          'SGD_lr'      : 0.01,\n","          'Adam_lr'     : 0.001,\n","          'overfitting_count' : 10,\n","          }"],"metadata":{"id":"VGiMwP870R1H","executionInfo":{"status":"ok","timestamp":1729091817534,"user_tz":-540,"elapsed":14,"user":{"displayName":"이도원","userId":"11243313302283747519"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# 새로운 CombinedPenDataset 사용\n","combined_dataset = CombinedPenDataset(penPositions, labels)\n","\n","# 데이터셋 크기 분할 (70% 훈련, 20% 검증, 10% 테스트)\n","train_size = int(0.7 * len(combined_dataset))\n","val_size = int(0.2 * len(combined_dataset))\n","test_size = len(combined_dataset) - train_size - val_size\n","\n","train_dataset_google, val_dataset_google, test_dataset_google = random_split(combined_dataset, [train_size, val_size, test_size])\n","# transform 적용\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(*config['data_stats_pickle']),\n","])\n","valid_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(*config['data_stats_pickle']),\n","])\n","\n","# DataLoader 생성\n","trainloader_google = DataLoader(train_dataset_google, batch_size=config['batch_size'], shuffle=True)\n","valloader_google = DataLoader(val_dataset_google, batch_size=config['batch_size'], shuffle=False)\n","testloader_google = DataLoader(test_dataset_google, batch_size=config['batch_size'], shuffle=False)\n","\n","\n","trainloader_google.transform = train_transform\n","valloader_google.transform = valid_transform"],"metadata":{"id":"YWGfVVYW0EM5","executionInfo":{"status":"ok","timestamp":1729091817534,"user_tz":-540,"elapsed":13,"user":{"displayName":"이도원","userId":"11243313302283747519"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8P8LurzTOhM","outputId":"71133f2b-34a8-451f-d9b4-1f273b5814f1","executionInfo":{"status":"ok","timestamp":1729091820158,"user_tz":-540,"elapsed":2636,"user":{"displayName":"이도원","userId":"11243313302283747519"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 14.5169\n","Epoch 2, Loss: 16.0384\n","Epoch 3, Loss: 12.2042\n","Epoch 4, Loss: 13.5972\n","Epoch 5, Loss: 14.7194\n"]}],"source":["from tqdm.notebook import tqdm  # tqdm의 노트북 전용 모듈\n","\n","for param in new_model_fine.parameters():\n","    param.requires_grad = False\n","\n","# 마지막 FC 레이어만 Fine-tuning\n","for param in new_model_fine.fc.parameters():\n","    param.requires_grad = True\n","\n","\n","# Optimizer에 마지막 레이어의 파라미터만 전달\n","optimizer = torch.optim.Adam(new_model_fine.fc.parameters(), lr=0.0001)  # 낮은 학습률 사용\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","def fine_tune(model, data_loader, optimizer, criterion, epochs=5):\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for inputs, labels in data_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n","\n","# 새로운 데이터에 대해 FC 레이어만 Fine-tuning 수행\n","fine_tune(new_model_fine, trainloader, optimizer, criterion)\n"]},{"cell_type":"code","source":["import random\n","\n","def selective_replay_training_with_sampling(model, train_loader, google_loader, optimizer, criterion, epochs=5, google_sample_size=32):\n","    model.train()\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            # google_loader에서 무작위로 데이터 샘플링\n","            google_inputs, google_labels = random_sample_from_dataloader(google_loader, google_sample_size)\n","            google_inputs, google_labels = google_inputs.to(device), google_labels.to(device)\n","\n","            google_outputs = model(google_inputs)\n","            google_loss = criterion(google_outputs, google_labels)\n","\n","            # Loss에 google_loader의 학습 손실 합산\n","            loss += google_loss\n","\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","\n","        print(f\"Epoch {epoch + 1}, Total Loss: {total_loss:.4f}\")\n","\n","# google_loader에서 랜덤 샘플링하는 함수 정의\n","def random_sample_from_dataloader(dataloader, sample_size):\n","    dataset = dataloader.dataset  # DataLoader에서 Dataset 가져오기\n","    indices = random.sample(range(len(dataset)), sample_size)  # 무작위 인덱스 선택\n","    samples = [dataset[i] for i in indices]  # 선택된 인덱스로 데이터 가져오기\n","\n","    inputs, labels = zip(*samples)\n","    return torch.stack(inputs), torch.tensor(labels)\n","\n","\n","# 학습 수행: googleloader에서 32개의 샘플을 랜덤하게 사용\n","selective_replay_training_with_sampling(new_model_Rehearsal, trainloader, trainloader_google, optimizer, criterion, google_sample_size=32)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ohIMZSvxBHjv","executionInfo":{"status":"ok","timestamp":1729091823606,"user_tz":-540,"elapsed":3451,"user":{"displayName":"이도원","userId":"11243313302283747519"}},"outputId":"01cfaebe-8a12-46ec-ffd7-5dd998b4e8e3"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Total Loss: 17.6197\n","Epoch 2, Total Loss: 17.5730\n","Epoch 3, Total Loss: 17.7693\n","Epoch 4, Total Loss: 18.3713\n","Epoch 5, Total Loss: 19.7612\n"]}]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","def distillation_loss(student_outputs, teacher_outputs, labels, temperature=5, alpha=0.5):\n","    # Cross-entropy loss with soft targets from teacher\n","    distillation_loss = F.kl_div(\n","        F.log_softmax(student_outputs / temperature, dim=1),\n","        F.softmax(teacher_outputs / temperature, dim=1),\n","        reduction=\"batchmean\"\n","    )\n","    # Standard cross-entropy loss with ground truth labels\n","    ce_loss = F.cross_entropy(student_outputs, labels)\n","    # Combine both losses\n","    return alpha * distillation_loss + (1 - alpha) * ce_loss\n","\n","\n","optimizer = torch.optim.Adam(new_model_student.parameters(), lr=0.0001)\n","\n","\n","# Knowledge Distillation을 통한 학습 루틴\n","def train_student(student_model, teacher_model, data_loader, optimizer, epochs=5):\n","    student_model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        for inputs, labels in data_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Teacher와 Student 모델의 출력 계산\n","            with torch.no_grad():\n","                teacher_outputs = teacher_model(inputs)\n","            student_outputs = student_model(inputs)\n","\n","            # Distillation Loss 계산\n","            loss = distillation_loss(student_outputs, teacher_outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","        print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n","\n","# Student 모델 학습 수행\n","train_student(new_model_student, original_model, trainloader, optimizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjXVYHmIBFrc","executionInfo":{"status":"ok","timestamp":1729091826739,"user_tz":-540,"elapsed":3136,"user":{"displayName":"이도원","userId":"11243313302283747519"}},"outputId":"27ba7be1-bc6a-4df2-9577-f38aa9cf104c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 7.2088\n","Epoch 2, Loss: 4.5834\n","Epoch 3, Loss: 2.6347\n","Epoch 4, Loss: 2.0076\n","Epoch 5, Loss: 1.4416\n"]}]},{"cell_type":"code","source":["def top_k_accuracy(output, target, k=1):\n","    with torch.no_grad():\n","        topk = output.topk(k, dim=1).indices\n","        correct = topk.eq(target.view(-1, 1).expand_as(topk))\n","        return correct.sum().item()"],"metadata":{"id":"aorMjoyC4iio","executionInfo":{"status":"ok","timestamp":1729091826739,"user_tz":-540,"elapsed":3,"user":{"displayName":"이도원","userId":"11243313302283747519"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":23,"metadata":{"id":"vP1JysKE5ZB5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729091827386,"user_tz":-540,"elapsed":3,"user":{"displayName":"이도원","userId":"11243313302283747519"}},"outputId":"4089b90f-1e95-4c70-b9e3-3ecb10e86396"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the new model_fine on the test images (Top 1): 40.000000000000%\n","Accuracy of the new model_fine on the test images (Top 5): 46.666666666667%\n","Accuracy of the new model_student on the test images (Top 1): 43.333333333333%\n","Accuracy of the new model_student on the test images (Top 5): 46.666666666667%\n","Accuracy of the new model_rehearsal on the test images (Top 1): 40.000000000000%\n","Accuracy of the new model_rehearsal on the test images (Top 5): 46.666666666667%\n","Accuracy of the original model on the test images (Top 1): 40.000000000000%\n","Accuracy of the original model on the test images (Top 5): 46.666666666667%\n"]}],"source":["correct_new_fine_top1 = 0\n","correct_new_fine_top5 = 0\n","total_new_fine = 0\n","\n","correct_original_top1 = 0\n","correct_original_top5 = 0\n","total_original = 0\n","\n","correct_new_student_top1 = 0\n","correct_new_student_top5 = 0\n","total_new_student = 0\n","\n","correct_new_Rehearsal_top1 = 0\n","correct_new_Rehearsal_top5 = 0\n","total_new_Rehearsal = 0\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data[0].float().to(device), data[1].to(device)\n","\n","        # Fine-tuned model\n","        outputs = new_model_fine(images)\n","        total_new_fine += labels.size(0)\n","        correct_new_fine_top1 += top_k_accuracy(outputs, labels, k=1)\n","        correct_new_fine_top5 += top_k_accuracy(outputs, labels, k=5)\n","\n","        # Original model\n","        outputs = original_model(images)\n","        total_original += labels.size(0)\n","        correct_original_top1 += top_k_accuracy(outputs, labels, k=1)\n","        correct_original_top5 += top_k_accuracy(outputs, labels, k=5)\n","\n","        # Student model\n","        outputs = new_model_student(images)\n","        total_new_student += labels.size(0)\n","        correct_new_student_top1 += top_k_accuracy(outputs, labels, k=1)\n","        correct_new_student_top5 += top_k_accuracy(outputs, labels, k=5)\n","\n","        # Rehearsal model\n","        outputs = new_model_Rehearsal(images)\n","        total_new_Rehearsal += labels.size(0)\n","        correct_new_Rehearsal_top1 += top_k_accuracy(outputs, labels, k=1)\n","        correct_new_Rehearsal_top5 += top_k_accuracy(outputs, labels, k=5)\n","\n","# Print accuracies\n","print(f'Accuracy of the new model_fine on the test images (Top 1): {100 * correct_new_fine_top1 / total_new_fine:.12f}%')\n","print(f'Accuracy of the new model_fine on the test images (Top 5): {100 * correct_new_fine_top5 / total_new_fine:.12f}%')\n","\n","print(f'Accuracy of the new model_student on the test images (Top 1): {100 * correct_new_student_top1 / total_new_student:.12f}%')\n","print(f'Accuracy of the new model_student on the test images (Top 5): {100 * correct_new_student_top5 / total_new_student:.12f}%')\n","\n","print(f'Accuracy of the new model_rehearsal on the test images (Top 1): {100 * correct_new_Rehearsal_top1 / total_new_Rehearsal:.12f}%')\n","print(f'Accuracy of the new model_rehearsal on the test images (Top 5): {100 * correct_new_Rehearsal_top5 / total_new_Rehearsal:.12f}%')\n","\n","print(f'Accuracy of the original model on the test images (Top 1): {100 * correct_original_top1 / total_original:.12f}%')\n","print(f'Accuracy of the original model on the test images (Top 5): {100 * correct_original_top5 / total_original:.12f}%')\n"]},{"cell_type":"code","source":["def top_k_accuracy(output, target, k=1):\n","    with torch.no_grad():\n","        topk = output.topk(k, dim=1).indices\n","        correct = topk.eq(target.view(-1, 1).expand_as(topk))\n","        return correct.sum().item()\n","\n","correct_new_fine_top1 = 0\n","correct_new_fine_top5 = 0\n","total_new_fine = 0\n","\n","correct_original_top1 = 0\n","correct_original_top5 = 0\n","total_original = 0\n","\n","correct_new_student_top1 = 0\n","correct_new_student_top5 = 0\n","total_new_student = 0\n","\n","correct_new_Rehearsal_top1 = 0\n","correct_new_Rehearsal_top5 = 0\n","total_new_Rehearsal = 0\n","\n","with torch.no_grad():\n","    for data in testloader_google:\n","        images, labels = data[0].float().to(device), data[1].to(device)\n","\n","        # Fine-tuned model\n","        outputs = new_model_fine(images)\n","        total_new_fine += labels.size(0)\n","        correct_new_fine_top1 += top_k_accuracy(outputs, labels, k=1)\n","        correct_new_fine_top5 += top_k_accuracy(outputs, labels, k=5)\n","\n","        # Original model\n","        outputs = original_model(images)\n","        total_original += labels.size(0)\n","        correct_original_top1 += top_k_accuracy(outputs, labels, k=1)\n","        correct_original_top5 += top_k_accuracy(outputs, labels, k=5)\n","\n","        # Student model\n","        outputs = new_model_student(images)\n","        total_new_student += labels.size(0)\n","        correct_new_student_top1 += top_k_accuracy(outputs, labels, k=1)\n","        correct_new_student_top5 += top_k_accuracy(outputs, labels, k=5)\n","\n","        # Rehearsal model\n","        outputs = new_model_Rehearsal(images)\n","        total_new_Rehearsal += labels.size(0)\n","        correct_new_Rehearsal_top1 += top_k_accuracy(outputs, labels, k=1)\n","        correct_new_Rehearsal_top5 += top_k_accuracy(outputs, labels, k=5)\n","\n","# Print accuracies\n","print(f'Accuracy of the new model_fine on the test images (Top 1): {100 * correct_new_fine_top1 / total_new_fine:.12f}%')\n","print(f'Accuracy of the new model_fine on the test images (Top 5): {100 * correct_new_fine_top5 / total_new_fine:.12f}%')\n","\n","print(f'Accuracy of the new model_student on the test images (Top 1): {100 * correct_new_student_top1 / total_new_student:.12f}%')\n","print(f'Accuracy of the new model_student on the test images (Top 5): {100 * correct_new_student_top5 / total_new_student:.12f}%')\n","\n","print(f'Accuracy of the new model_rehearsal on the test images (Top 1): {100 * correct_new_Rehearsal_top1 / total_new_Rehearsal:.12f}%')\n","print(f'Accuracy of the new model_rehearsal on the test images (Top 5): {100 * correct_new_Rehearsal_top5 / total_new_Rehearsal:.12f}%')\n","\n","print(f'Accuracy of the original model on the test images (Top 1): {100 * correct_original_top1 / total_original:.12f}%')\n","print(f'Accuracy of the original model on the test images (Top 5): {100 * correct_original_top5 / total_original:.12f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIqtG7q40H3Z","executionInfo":{"status":"ok","timestamp":1729092417855,"user_tz":-540,"elapsed":590470,"user":{"displayName":"이도원","userId":"11243313302283747519"}},"outputId":"9aad21d1-a1b3-4ef5-cf45-37bdd4907fa9"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the new model_fine on the test images (Top 1): 78.497906602254%\n","Accuracy of the new model_fine on the test images (Top 5): 96.269887278583%\n","Accuracy of the new model_student on the test images (Top 1): 76.051529790660%\n","Accuracy of the new model_student on the test images (Top 5): 95.472785829308%\n","Accuracy of the new model_rehearsal on the test images (Top 1): 78.875362318841%\n","Accuracy of the new model_rehearsal on the test images (Top 5): 96.369404186795%\n","Accuracy of the original model on the test images (Top 1): 78.875362318841%\n","Accuracy of the original model on the test images (Top 5): 96.369404186795%\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}